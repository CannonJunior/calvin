#!/usr/bin/env python3
"""
Verified Earnings Research System
Systematically researches all S&P 500 companies for accurate earnings data with source links
"""

import json
import logging
import time
import requests
from datetime import datetime, date, timedelta
from typing import List, Dict, Optional
import psycopg2
from psycopg2.extras import RealDictCursor

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class VerifiedEarningsResearcher:
    def __init__(self):
        """Initialize the verified earnings research system"""
        
        # Database configuration
        self.db_config = {
            'host': 'localhost',
            'port': 5432,
            'database': 'calvin_earnings',
            'user': 'calvin_user',
            'password': 'calvin_pass'
        }
        
        self.conn = None
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # S&P 500 companies - will be loaded from reliable source
        self.sp500_companies = []
        
        # Data validation requirements
        self.required_fields = [
            'symbol', 'company_name', 'earnings_date', 'source_url', 'market_cap'
        ]
    
    def connect_to_database(self):
        """Connect to PostgreSQL database"""
        try:
            self.conn = psycopg2.connect(**self.db_config)
            self.conn.autocommit = True
            logger.info("‚úÖ Connected to PostgreSQL database")
            return True
        except Exception as e:
            logger.error(f"‚ùå Failed to connect to database: {e}")
            return False
    
    def clear_existing_data(self):
        """Clear all existing earnings data"""
        if not self.conn:
            logger.error("No database connection")
            return False
        
        try:
            cursor = self.conn.cursor()
            
            # Clear earnings data
            cursor.execute("DELETE FROM earnings")
            earnings_deleted = cursor.rowcount
            
            cursor.close()
            logger.info(f"üóëÔ∏è Cleared {earnings_deleted} existing earnings records")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Failed to clear existing data: {e}")
            return False
    
    def load_sp500_companies(self):
        """Load current S&P 500 companies from reliable sources"""
        # Using a reliable financial data source
        sp500_list = [
            # Top 50 by market cap - this is a starting subset
            {'symbol': 'AAPL', 'name': 'Apple Inc.', 'sector': 'Information Technology'},
            {'symbol': 'MSFT', 'name': 'Microsoft Corporation', 'sector': 'Information Technology'},
            {'symbol': 'NVDA', 'name': 'NVIDIA Corporation', 'sector': 'Information Technology'},
            {'symbol': 'AMZN', 'name': 'Amazon.com, Inc.', 'sector': 'Consumer Discretionary'},
            {'symbol': 'GOOGL', 'name': 'Alphabet Inc.', 'sector': 'Communication Services'},
            {'symbol': 'GOOG', 'name': 'Alphabet Inc.', 'sector': 'Communication Services'},
            {'symbol': 'META', 'name': 'Meta Platforms, Inc.', 'sector': 'Communication Services'},
            {'symbol': 'TSLA', 'name': 'Tesla, Inc.', 'sector': 'Consumer Discretionary'},
            {'symbol': 'BRK.B', 'name': 'Berkshire Hathaway Inc.', 'sector': 'Financials'},
            {'symbol': 'TSM', 'name': 'Taiwan Semiconductor Manufacturing Company Limited', 'sector': 'Information Technology'},
            {'symbol': 'LLY', 'name': 'Eli Lilly and Company', 'sector': 'Health Care'},
            {'symbol': 'V', 'name': 'Visa Inc.', 'sector': 'Financials'},
            {'symbol': 'JPM', 'name': 'JPMorgan Chase & Co.', 'sector': 'Financials'},
            {'symbol': 'AVGO', 'name': 'Broadcom Inc.', 'sector': 'Information Technology'},
            {'symbol': 'UNH', 'name': 'UnitedHealth Group Incorporated', 'sector': 'Health Care'},
            {'symbol': 'XOM', 'name': 'Exxon Mobil Corporation', 'sector': 'Energy'},
            {'symbol': 'MA', 'name': 'Mastercard Incorporated', 'sector': 'Financials'},
            {'symbol': 'ORCL', 'name': 'Oracle Corporation', 'sector': 'Information Technology'},
            {'symbol': 'HD', 'name': 'The Home Depot, Inc.', 'sector': 'Consumer Discretionary'},
            {'symbol': 'PG', 'name': 'The Procter & Gamble Company', 'sector': 'Consumer Staples'},
            # Add more companies systematically...
        ]
        
        self.sp500_companies = sp500_list
        logger.info(f"üìä Loaded {len(self.sp500_companies)} S&P 500 companies for research")
        return True
    
    def research_company_earnings(self, symbol: str, company_name: str) -> List[Dict]:
        """Research earnings data for a specific company with source verification"""
        logger.info(f"üîç Researching earnings for {symbol} - {company_name}")
        
        earnings_data = []
        
        try:
            # Research current market cap from reliable source
            market_cap_data = self.get_verified_market_cap(symbol)
            
            # Research past earnings with sources
            past_earnings = self.get_verified_past_earnings(symbol)
            
            # Research future earnings dates with sources
            future_earnings = self.get_verified_future_earnings(symbol)
            
            # Combine all earnings data
            earnings_data.extend(past_earnings)
            earnings_data.extend(future_earnings)
            
            # Add market cap to all entries
            for earning in earnings_data:
                earning.update(market_cap_data)
                earning['symbol'] = symbol
                earning['company_name'] = company_name
            
            logger.info(f"‚úÖ Found {len(earnings_data)} verified earnings entries for {symbol}")
            return earnings_data
            
        except Exception as e:
            logger.error(f"‚ùå Failed to research {symbol}: {e}")
            return []
    
    def get_verified_market_cap(self, symbol: str) -> Dict:
        """Get verified current market cap with source"""
        # This would use reliable financial APIs with proper attribution
        # For now, return placeholder structure
        return {
            'market_cap': None,  # Will be filled with real data
            'market_cap_source': f"https://finance.yahoo.com/quote/{symbol}",
            'market_cap_date': datetime.now().isoformat()
        }
    
    def get_verified_past_earnings(self, symbol: str) -> List[Dict]:
        """Get verified past earnings with sources"""
        # This would research actual past earnings from SEC filings, company press releases, etc.
        # For now, return empty list - will only include data with verified sources
        return []
    
    def get_verified_future_earnings(self, symbol: str) -> List[Dict]:
        """Get verified future earnings dates with sources"""
        # This would research actual earnings calendars from reliable sources
        # For now, return empty list - will only include data with verified sources
        return []
    
    def validate_earnings_data(self, earning_data: Dict) -> bool:
        """Validate that earnings data meets requirements"""
        
        # Check required fields
        for field in self.required_fields:
            if field not in earning_data:
                logger.warning(f"Missing required field: {field}")
                return False
        
        # Check source URL is valid
        if not earning_data.get('source_url') or not earning_data['source_url'].startswith('http'):
            logger.warning(f"Invalid or missing source URL: {earning_data.get('source_url')}")
            return False
        
        # Check earnings date is valid
        try:
            datetime.fromisoformat(earning_data['earnings_date'].replace('Z', '+00:00'))
        except:
            logger.warning(f"Invalid earnings date: {earning_data.get('earnings_date')}")
            return False
        
        return True
    
    def store_verified_earnings(self, earnings_data: List[Dict]) -> bool:
        """Store only verified earnings data with sources"""
        if not self.conn:
            logger.error("No database connection")
            return False
        
        validated_count = 0
        rejected_count = 0
        
        try:
            cursor = self.conn.cursor()
            
            for earning in earnings_data:
                if self.validate_earnings_data(earning):
                    # Add new schema fields for verification
                    query = """
                        INSERT INTO earnings (
                            symbol, company_name, earnings_date, quarter, year,
                            actual_eps, estimated_eps, beat_miss_meet, surprise_percent,
                            confidence_score, consensus_rating, announcement_time,
                            market_cap, source_url, data_verified_date, created_at
                        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, CURRENT_TIMESTAMP)
                        ON CONFLICT (symbol, earnings_date, quarter, year) DO NOTHING
                    """
                    
                    # Parse date for quarter/year
                    earnings_date = datetime.fromisoformat(earning['earnings_date'].replace('Z', '+00:00'))
                    quarter = ((earnings_date.month - 1) // 3) + 1
                    year = earnings_date.year
                    
                    cursor.execute(query, (
                        earning['symbol'],
                        earning['company_name'],
                        earnings_date.date(),
                        quarter,
                        year,
                        earning.get('actual_eps'),
                        earning.get('estimated_eps'),
                        earning.get('beat_miss_meet'),
                        earning.get('surprise_percent'),
                        earning.get('confidence_score', 0.9),
                        earning.get('consensus_rating'),
                        earning.get('announcement_time'),
                        earning.get('market_cap'),
                        earning['source_url'],
                        datetime.now().date()
                    ))
                    
                    validated_count += 1
                else:
                    rejected_count += 1
                    logger.warning(f"Rejected earnings data for {earning.get('symbol')} - missing source or validation failed")
            
            cursor.close()
            logger.info(f"‚úÖ Stored {validated_count} verified earnings records, rejected {rejected_count}")
            return validated_count > 0
            
        except Exception as e:
            logger.error(f"‚ùå Failed to store earnings data: {e}")
            return False
    
    def research_all_sp500_earnings(self):
        """Research earnings for all S&P 500 companies"""
        logger.info("üöÄ Starting comprehensive S&P 500 earnings research...")
        
        total_companies = len(self.sp500_companies)
        processed_count = 0
        success_count = 0
        
        for i, company in enumerate(self.sp500_companies):
            logger.info(f"üìä Processing {company['symbol']} ({i+1}/{total_companies})")
            
            try:
                earnings_data = self.research_company_earnings(
                    company['symbol'], 
                    company['name']
                )
                
                if earnings_data:
                    if self.store_verified_earnings(earnings_data):
                        success_count += 1
                
                processed_count += 1
                
                # Rate limiting
                time.sleep(1)
                
            except Exception as e:
                logger.error(f"‚ùå Error processing {company['symbol']}: {e}")
        
        logger.info(f"üéâ Research complete: {processed_count} companies processed, {success_count} with verified data")
        return success_count > 0
    
    def add_source_url_field(self):
        """Add source_url field to earnings table if not exists"""
        if not self.conn:
            return False
        
        try:
            cursor = self.conn.cursor()
            
            # Add new columns for data verification
            cursor.execute("""
                ALTER TABLE earnings 
                ADD COLUMN IF NOT EXISTS source_url TEXT,
                ADD COLUMN IF NOT EXISTS data_verified_date DATE,
                ADD COLUMN IF NOT EXISTS market_cap_source TEXT,
                ADD COLUMN IF NOT EXISTS market_cap_date TIMESTAMP
            """)
            
            cursor.close()
            logger.info("‚úÖ Added source tracking fields to earnings table")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Failed to add source fields: {e}")
            return False
    
    def run_verified_research(self):
        """Run the complete verified earnings research process"""
        logger.info("üöÄ Starting verified earnings research system...")
        
        # Connect to database
        if not self.connect_to_database():
            return False
        
        # Add source tracking fields
        if not self.add_source_url_field():
            return False
        
        # Clear existing unverified data
        if not self.clear_existing_data():
            return False
        
        # Load S&P 500 companies
        if not self.load_sp500_companies():
            return False
        
        # Research all companies with verification
        return self.research_all_sp500_earnings()


def main():
    """Main function"""
    researcher = VerifiedEarningsResearcher()
    
    logger.info("‚ö†Ô∏è  IMPORTANT: This system only publishes earnings data with verified sources")
    logger.info("‚ö†Ô∏è  Data without source links will be rejected")
    
    researcher.run_verified_research()


if __name__ == "__main__":
    main()